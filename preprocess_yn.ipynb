{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf717c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "COLLECTION_NAME = \"tax_law\"\n",
    "PERSIST_DIRECTORY = \"tax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e0a070fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(folder_path, format=\".pdf\"):\n",
    "    \"\"\"\n",
    "    주어진 폴더 내에 있는 PDF 파일들의 이름을 리스트로 반환합니다.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    try:\n",
    "        all_files = os.listdir(folder_path)\n",
    "        pdf_files = [file.replace(format,\"\") for file in all_files if file.lower().endswith(format)]\n",
    "        \n",
    "        return pdf_files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: 폴더 '{folder_path}'를 찾을 수 없습니다.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6232293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "def load_and_split_tax_law(file_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    PDF 파일들을 처리하여 임베딩을 Chroma Vector Store에 저장합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    file_path = f\"data/tax_law/{file_name}.pdf\"\n",
    "\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    load_document = loader.load()\n",
    "\n",
    "    # 전처리 - 반복 텍스트 삭제\n",
    "    delete_pattern_1 = rf\"법제처\\s*\\d+\\s*국가법령정보센터\\n{file_name.replace('_', ' ')}\\n\" \n",
    "    delete_pattern_2 = r'\\[[\\s\\S]*?\\]'\n",
    "    delete_pattern_3 = r'<[\\s\\S]*?>'\n",
    "    \n",
    "    full_text = \" \".join([document.page_content for document in load_document])\n",
    "    \n",
    "    full_text = re.sub(delete_pattern_1, \"\", full_text)\n",
    "    full_text=re.sub(delete_pattern_2, '', full_text)\n",
    "    full_text=re.sub(delete_pattern_3, '', full_text)\n",
    "    \n",
    "    # 전처리 - split\n",
    "    split_pattern = r\"\\s*\\n(제\\d+조(?:의\\d+)?(?:\\([^)]*\\))?)(?=\\s|$)\"\n",
    "    chunks = re.split(split_pattern, full_text)\n",
    "\n",
    "    chunk_docs = []  # 최종 return 할 list\n",
    "    connected_chunks = [] \n",
    "    current_chunk = \"\"\n",
    "    is_buchik_section = False \n",
    "    \n",
    "    # 전처리 - 일반 조항과 부칙의 조항과 구별하기 위해 접두어 '부칙-'을 넣음.\n",
    "    for chunk in chunks:\n",
    "        if re.search(r\"\\n\\s*부칙\", chunk): \n",
    "            is_buchik_section = True\n",
    "\n",
    "        if chunk.startswith(\"제\") and \"조\" in chunk: \n",
    "            if is_buchik_section:\n",
    "                chunk = \"부칙-\" + chunk\n",
    "\n",
    "            if current_chunk:\n",
    "                connected_chunks.append(current_chunk.strip())\n",
    "            current_chunk = chunk \n",
    "        else:\n",
    "            current_chunk += f\" {chunk}\" \n",
    "\n",
    "    if current_chunk:\n",
    "        connected_chunks.append(current_chunk.strip())\n",
    "\n",
    "    for chunk in connected_chunks:\n",
    "        pattern =  r\"^(?:부칙-)?제\\d+조(?:의\\d*)?(?:\\([^)]*\\))?\"\n",
    "\n",
    "        keyword = []\n",
    "\n",
    "        keyword.append(file_name)\n",
    "        \n",
    "        match = re.search(pattern, chunk)\n",
    "        if match:\n",
    "            word = match.group()\n",
    "            word = re.sub(r'\\s+', ' ', word)\n",
    "            keyword.append(word) \n",
    "            \n",
    "        doc = Document(metadata={\"title\": file_name, \"keyword\":keyword, \"effective_year\": 2025 }, page_content=chunk),\n",
    "        \n",
    "        chunk_docs.extend(doc)\n",
    "        \n",
    "    return chunk_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "20d64a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(len(all_docs))\n",
    "# print(all_docs[1])\n",
    "# embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# vector_store = Chroma.from_documents(\n",
    "#     documents=all_docs,\n",
    "#     embedding=embedding_model,\n",
    "#     collection_name=COLLECTION_NAME,\n",
    "#     persist_directory=PERSIST_DIRECTORY\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "all_documents = []\n",
    "# load - 세법 \n",
    "law_files = get_file_names(\"data/tax_law\")\n",
    "for file in law_files:\n",
    "    all_documents.extend(load_and_split_tax_law(file))\n",
    "# load - 세법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7863fac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5431"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce2c72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template 생성\n",
    "messages = [\n",
    "        (\"ai\", \"\"\"\n",
    "        당신은 대한민국 세법에 대해 전문적으로 학습된 AI 도우미입니다. 저장된 세법 조항 데이터를 기반으로 사용자 질문에 답변하세요.\n",
    "\n",
    "        - 모든 답변은 학습된 세법 데이터 내에서만 유효한 정보를 바탕으로 작성하세요. 데이터에 없는 내용은 추측하거나 임의로 생성하지 마세요.\n",
    "        - 질문에 명확한 답변이 없거나 데이터 내에서 찾을 수 없는 경우, 정직하게 \"잘 모르겠습니다.\"라고 말하고, 새로운 질문을 유도하세요.\n",
    "        - 질문이 포함된 조항뿐 아니라, 필요 시 서로 연관된 다른 조항도 참고하여 답변의 정확성과 완성도를 높이세요.\n",
    "        - 사용자가 이해하기 쉽게 답변을 구성하며, 중요한 키워드나 법 조항은 명확히 표시하세요.\n",
    "        - 세법과 관련된 복잡한 질문에 대해서는 관련 조항 번호와 요약된 내용을 포함하여 답변을 제공하세요.\n",
    "        \n",
    "        추가 규칙:\n",
    "        답변은 간결하고 명료하게 작성하되, 필요한 경우 관련 조항의 전문을 추가적으로 인용하세요.\n",
    "        세법 용어를 사용자 친화적으로 설명하여 비전문가도 쉽게 이해할 수 있도록 하세요.\n",
    "        질문을 완전히 이해하기 어렵거나 모호할 경우, 사용자가 구체적으로 질문을 다시 작성할 수 있도록 유도하는 후속 질문을 하세요.\n",
    "\n",
    "\t답변 후, 사용자에게 필요할 것 같은 정보를 바탕으로 두 가지 후속 질문을 제안하세요. 각 질문의 앞뒤에 한 줄씩 띄어쓰기를 하세요. 이 질문은 원래 주제와 관련된 내용이어야 합니다.\n",
    "\t특정 법률 조항이나 제도가 언급될 경우, 근거가 되는 세법 조문, 시행령, 또는 관련 자료를 명시합니다.\n",
    "        모든 답변은 사용자에게 법적 조언이 아닌 정보 제공 목적으로 작성된 것임을 명확히 합니다. \n",
    "\t{context}\")\"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate(messages)\n",
    "# 모델\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Chain 구성 retriever(관련문서 조회) -> prompt_template(prompt 생성) -> model(정답) -> output parser\n",
    "chain = {\"context\":retriever, \"question\": RunnablePassthrough()} | prompt_template | model | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.invoke(\"개별소비세법이 뭐야?\")\n",
    "# chain.invoke(\"개별소비세법이 제1조가 뭐야\")\n",
    "# chain.invoke(\"교통_에너지_환경세법 뭐야?\")\n",
    "chain.invoke(\"조세범 처벌절차법의 정의해줘\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717ab88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e748211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
